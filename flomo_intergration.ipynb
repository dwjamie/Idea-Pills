{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flomo Intergration（闪念胶囊）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tiktoken\n",
    "import requests\n",
    "\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import speech_recognition as sr\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "import promptlayer\n",
    "promptlayer.api_key = os.getenv(\"PROMPTLAYER_API_KEY\")\n",
    "\n",
    "openai = promptlayer.openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "flomo_api = os.getenv(\"FLOMO_API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = \"gpt-3.5-turbo\"\n",
    "MODEL = \"gpt-4\"\n",
    "TOKEN_LIMIT = 4096"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string, model=MODEL):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages, model=MODEL):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":  # if there's a name, the role is omitted\n",
    "                num_tokens += -1  # role is always required and always 1 token\n",
    "    num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "    \n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_messages(messages):\n",
    "    for message in messages:\n",
    "        if 'name' not in message:\n",
    "            print(f\"{message['role']}:\\n{message['content']}\\n\")\n",
    "        else:\n",
    "            print(f\"{message['role']} \\ {message['name']}:\\n{message['content']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_roles(messages):\n",
    "    reversed_messages = []\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            message[\"role\"] = \"user\"\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            message[\"role\"] = \"assistant\"\n",
    "        reversed_messages.append(message)\n",
    "    return reversed_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answering(prompt, system_message=\"You are ChatGPT, a large language model trained by OpenAI. Answer as concisely as possible.\", temperature=0.0, pl_tags=[\"test\"]):\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        pl_tags=pl_tags,\n",
    "    )\n",
    "    \n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation(prompt, messages, temperature=0.0, pl_tags=[\"test\"]):\n",
    "    \n",
    "    messages = messages + [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        pl_tags=pl_tags,\n",
    "    )\n",
    "\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response[\"choices\"][0][\"message\"][\"content\"]})\n",
    "\n",
    "    show_messages(messages)\n",
    "    \n",
    "    return messages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/selected_memos.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    memos = f.read()\n",
    "\n",
    "with open(\"data/tags.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    tags = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = f\"\"\"\n",
    "我需要你作为一个memo生成器，帮我从比较随意的、口语化的、不严谨的语言中，去掉一些不必要的部分，稍微整理得结构化一些，然后按照我的口吻（下面会给出示例），生成一个memo。并打上1-3个tag。\n",
    "\n",
    "我目前总共有这些tag（“/”代表子tag）：\n",
    "{tags}\n",
    "\n",
    "以下是我以前的一些memo，你可以参考一下：\n",
    "{memos}\n",
    "\"\"\"\n",
    "\n",
    "def generate_memo(original_content, temperature=0.0, pl_tags=[\"flomo-intergration\"]):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instruction},\n",
    "        {\"role\": \"user\", \"content\": f\"Original content:\\n{original_content}\\n\\nMemo:\"},\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        pl_tags=pl_tags,\n",
    "    )\n",
    "\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_memos_to_flomo(memo):\n",
    "    response = requests.post(flomo_api, {\"content\": memo})\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print('\\n已发送到Flomo！')\n",
    "    else:\n",
    "        print('\\n请求失败：', response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "闪念胶囊产品功能想法\n",
      "考虑开发一个闪念胶囊功能，通过结合语音记录，让用户随时随地记录和回听自己的想法，避免遗忘。\n",
      "#想法 #生活/产品\n",
      "\n",
      "已发送到Flomo！\n"
     ]
    }
   ],
   "source": [
    "original_content = '我刚刚在想，能不能做一个闪念胶囊的产品功能出来，应该会很好用。感觉不错的，主要就是结合语音功能来记录，然后可以随时随地听到，这样就不用担心忘记了。'\n",
    "generated_memo = generate_memo(original_content)\n",
    "print(generated_memo)\n",
    "send_memos_to_flomo(generated_memo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56eb116e8b4e46a0806226b80a8b9a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='开始录音', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始录音，请说话...\n",
      "\n",
      "录音结束，识别中...\n",
      "\n",
      "识别成功！语音内容： 你好这是我的第1条录音那么我也不知道要说什么\n",
      "\n",
      "生成Memo：\n",
      "第1条录音\n",
      "今天进行了第一次录音尝试，内容较为随意，未确定具体话题。\n",
      "#杂记\n",
      "\n",
      "已发送到Flomo！\n"
     ]
    }
   ],
   "source": [
    "def wav_to_text(wav_file_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    with sr.AudioFile(wav_file_path) as audio_file:\n",
    "        audio_data = recognizer.record(audio_file)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio_data, language=\"zh-CN\")\n",
    "            print(\"\\n识别成功！语音内容：\", text)\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"\\n语音无法识别，请重试！\")\n",
    "        except sr.RequestError as e:\n",
    "            print(\"\\nCould not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "\n",
    "def record_from_mic(button):\n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 44100\n",
    "    RECORD_SECONDS = 5\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"开始录音，请说话...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"\\n录音结束，识别中...\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open('data/audio.wav', 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "    original_content = wav_to_text('data/audio.wav')\n",
    "    generated_memo = generate_memo(original_content)\n",
    "    print('\\n生成Memo：\\n' + generated_memo)\n",
    "    send_memos_to_flomo(generated_memo)\n",
    "\n",
    "\n",
    "record_button = widgets.Button(description=\"开始录音\")\n",
    "record_button.on_click(record_from_mic)\n",
    "display(record_button)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
